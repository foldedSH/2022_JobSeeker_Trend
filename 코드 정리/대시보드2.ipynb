{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import requests, bs4\n",
    "from urllib.parse import unquote\n",
    "\n",
    "# 텍스트 요약\n",
    "from krwordrank.sentence import summarize_with_sentences\n",
    "from krwordrank.word import KRWordRank\n",
    "from krwordrank.word import summarize_with_keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 강소기업 정보/탐방기 API\n",
    "- 'busiNo': 사업자 등록번호\n",
    "- 'compNm': 사업자명\n",
    "- 'regionNm': 지역\n",
    "- 'indTypeNm': 업종명\n",
    "- 'smlgntCoClcd': 강소기업 카테고리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "My_API_Key = unquote('#########')  # 본인 인증키\n",
    "\n",
    "# 추출 컬럼명\n",
    "data_idx = ['busiNo', 'compNm', 'regionNm', 'indTypeNm', 'smlgntCoClcd']\n",
    "value_idx = [[] for _ in range(len(data_idx))]\n",
    "data = dict(zip(data_idx, value_idx)) # 각 컬럼 초기화\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1페이지 ~ 1000페이지 탐색\n",
    "for page in range(1, 1001):\n",
    "    # Service URL + 인증키\n",
    "    xmlUrl = f'''http://openapi.work.go.kr/opi/opi/opia/corpInfoReportApi.do?authKey={My_API_Key}\\\n",
    "            &returnType=XML&callTp=L&startPage={page}&display=100'''\n",
    "\n",
    "    response = requests.get(xmlUrl).text.encode('utf-8')\n",
    "    xmlobj = bs4.BeautifulSoup(response, 'lxml-xml')\n",
    "    wanted = xmlobj.find_all(\"company\")\n",
    "    if wanted == []:\n",
    "        break\n",
    "\n",
    "    for vals in wanted:\n",
    "        data[\"busiNo\"].append(vals.find('busiNo').text)\n",
    "        data[\"compNm\"].append(vals.find('compNm').text)\n",
    "\n",
    "        try:\n",
    "            data[\"regionNm\"].append(vals.find('regionNm').text)\n",
    "        except AttributeError:\n",
    "            data[\"regionNm\"].append(np.nan)\n",
    "            #print(\"regionNm >> \", vals)\n",
    "\n",
    "        try:\n",
    "            data[\"smlgntCoClcd\"].append(vals.find('smlgntCoClcd').text)\n",
    "        except AttributeError:\n",
    "            data[\"smlgntCoClcd\"].append(np.nan)\n",
    "            #print(\"smlgntCoClcd >> \", vals)\n",
    "\n",
    "        data[\"indTypeNm\"].append(vals.find('indTypeNm').text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 강소기업 정보\n",
    "data = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 강소기업 탐방기 데이터 저장\n",
    "QA_data = {'busiNo':[], 'compNm':[], 'Q':[], 'A':[]}\n",
    "for row in data.iterrows():\n",
    "    busiNO = row[1]['busiNo']\n",
    "    comp = row[1]['compNm']\n",
    "\n",
    "    xmlUrl = f'''http://openapi.work.go.kr/opi/opi/opia/corpInfoReportApi.do?authKey={My_API_Key}\\\n",
    "                &returnType=XML&callTp=D&busiNo={busiNO}'''\n",
    "\n",
    "    response = requests.get(xmlUrl).text.encode('utf-8')\n",
    "    xmlobj = bs4.BeautifulSoup(response, 'lxml-xml')\n",
    "    QAs = xmlobj.find(\"compDtl\").find_all('coInqReprt') # Q&A 정보\n",
    "    for qa in QAs:\n",
    "        QA_data['busiNo'] += [busiNO]\n",
    "        QA_data['compNm'] += [comp]\n",
    "        QA_data['Q'] += [qa.find(\"contSubtitle\").text]\n",
    "        QA_data['A'] += [qa.find(\"contCont\").text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QA_data = pd.DataFrame(QA_data)\n",
    "QA_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QA_data.to_csv(\"../data/탐방기업_QA.csv\", index=False, encoding = 'UTF-8-sig')\n",
    "QA_data.to_excel(\"../data/탐방기업_QA.xlsx\", index=False, encoding = 'UTF-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q&A 단어/어절 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# engine='python': csv 파일 한글명 읽기 위해\n",
    "QA = pd.read_csv(\"탐방기업_QA.csv\", engine='python', encoding = 'utf-8-sig')\n",
    "QA.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어/어절 분리\n",
    "okt = Okt()\n",
    "for row in QA.iterrows():\n",
    "    try:\n",
    "        nouns = okt.nouns(row[1]['A'])\n",
    "        QA.at[row[0], 'nouns'] = ','.join(nouns)\n",
    "        QA.at[row[0], 'phrases'] = ','.join(okt.phrases(row[1]['A']))\n",
    "    except AssertionError:\n",
    "        QA.at[row[0], 'nouns'] = np.nan\n",
    "        QA.at[row[0], 'phrases'] = np.nan\n",
    "\n",
    "QA = QA.dropna().reset_index(drop='index')\n",
    "QA.to_csv(\"QA_tokenData.csv\", index=False, encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q&A 텍스트 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()\n",
    "\n",
    "def preprocessing(review):\n",
    "    total_review = ''\n",
    "    #인풋리뷰\n",
    "    for row in review.iterrows():\n",
    "        r = row[1]['A']\n",
    "        #하나의 리뷰에서 문장 단위로 자르기\n",
    "        sentence = r\n",
    "        sentence = re.sub('\\n','',sentence)\n",
    "        sentence = re.sub('\\u200b','',sentence)\n",
    "        sentence = re.sub('\\xa0','',sentence)\n",
    "        sentence = re.sub('([a-zA-Z])','',sentence)\n",
    "        sentence = re.sub('[ㄱ-ㅎㅏ-ㅣ]+','',sentence)\n",
    "        sentence = re.sub('[-=+,#/\\?:^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》]','',sentence)\n",
    "\n",
    "        if len(sentence) == 0:\n",
    "            continue\n",
    "        sentence = okt.phrases(sentence)\n",
    "        \n",
    "        word = []\n",
    "        for i in sentence:\n",
    "            if i == '디자':\n",
    "                i = '디자인'\n",
    "            elif i == '시스':\n",
    "                i = '시스템'\n",
    "            elif i == '네트':\n",
    "                i = '네트워크'\n",
    "            word.append(i)\n",
    "        word = ' '.join(word)\n",
    "        word += '. '\n",
    "        total_review += word\n",
    "    return total_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QA2 = QA.iloc[np.where(QA['Q'].str.contains('복리|복지'))] # 복리/복지 관련 질문에 대한 답변"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_data = {'busiNo':[], 'company':[], 'tag':[]}\n",
    "\n",
    "# 키워드 추출\n",
    "for b_idx, comp_qa in list(QA2.groupby(\"busiNo\")):\n",
    "    print(b_idx)\n",
    "    st = ''\n",
    "    name = comp_qa['compNm'].iloc[0]\n",
    "    texts = preprocessing(comp_qa)\n",
    "    st += texts\n",
    "    texts = st.split('. ')\n",
    "\n",
    "    # 제외할 키워드 목록\n",
    "    stopwords = {\"있습니다.\", \"또한\", '저희', '회사', '대한', '때문', '통해', \n",
    "                '경우', '위해', '각종', '직원의', '업무', '직원들', '당사', '충족',\n",
    "                '후생','황금','화성의','현지','현재','허가'}\n",
    "    try:\n",
    "        keywords, sents = summarize_with_sentences(\n",
    "                                               texts, \n",
    "                                               stopwords = stopwords,\n",
    "                                               num_keywords=100, \n",
    "                                               num_keysents=10\n",
    "                                               )\n",
    "    except ValueError:\n",
    "        keywords, sents = summarize_with_sentences(\n",
    "                                               texts*5, \n",
    "                                               stopwords = stopwords,\n",
    "                                               num_keywords=100, \n",
    "                                               num_keysents=10\n",
    "                                               )\n",
    "        \n",
    "    for word, r in sorted(keywords.items(), key=lambda x:x[1], reverse=True)[:7]:\n",
    "        #print('%8s:\\t%.4f' % (word, r))\n",
    "        print('#%s' % word)\n",
    "        token_data['busiNo'].append(b_idx)\n",
    "        token_data['company'].append(name)\n",
    "        token_data['tag'].append(word)\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(token_data).to_csv(\"QA_tag4_3.csv\", index=False, encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 복지 단어 개수 count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"../data/QA_tag4_3.csv\")\n",
    "data = data[['busiNo', 'company', 'tag']]\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.DataFrame(data.value_counts(subset=['company']))\n",
    "data1 = data1.reset_index()\n",
    "data1.columns = ['company', 'num']\n",
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.to_csv(r\"../data/복지_기업별단어수.csv\", index=False, encoding=\"cp949\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 뉴스 크롤링 및 뉴스 기사 개수 count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_idx = ['keyword', 'title']\n",
    "value_idx = [[] for _ in range(len(data_idx))]\n",
    "data = dict(zip(data_idx, value_idx)) # 각 컬럼 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기업명 가져오기\n",
    "name = pd.read_excel(r\"../data/탐방기업_QA.xlsx\")\n",
    "names = name[['compNm']].drop_duplicates(ignore_index = True)\n",
    "names.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기업 별 뉴스 기사 카운팅\n",
    "for row in names.iterrows():\n",
    "    keyword = row[1]['compNm']\n",
    "    lastPage = 10\n",
    "    pageNum = 1\n",
    "    for i in range(1, int(lastPage) * 10, 10):\n",
    "        print(pageNum)\n",
    "        response = requests.get(f\"https://search.naver.com/search.naver?where=news&sm=tab_jum&query={keyword}&start={i}\")\n",
    "        html = response.text\n",
    "\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        links = soup.select(\".news_tit\") #결과가 리스트로 나옴\n",
    "        #print(links)\n",
    "\n",
    "        for link in links:\n",
    "            title = link.text # 태그 안에 텍스트요소를 가져온다.\n",
    "            url = link.attrs['href'] # href의 속성값을 가져온다.\n",
    "            # print(title)\n",
    "            # print(url)\n",
    "            data['title'].append(title)\n",
    "            # data['url'].append(url)\n",
    "            data['keyword'].append(keyword)\n",
    "\n",
    "\n",
    "        pageNum = pageNum + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(data)\n",
    "data.to_csv(r\"../data/뉴스검색수.csv\", index=False, encoding = 'UTF-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.DataFrame(data.value_counts(subset=['keyword']))\n",
    "data1 = data1.reset_index()\n",
    "data1.columns = ['company', 'num']\n",
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.to_csv(r\"../data/뉴스_기업별단어수.csv\", index=False, encoding=\"cp949\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 국민연금데이터와 기업탐방 데이터 병합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv(r\"./data/탐방기업_QA.csv\")\n",
    "data1['name'] = data1['compNm']\n",
    "data1['name'].replace(\"주식회사\", '', regex=True, inplace=True)\n",
    "data1['name'].replace(\"\\(주\\)\", '', regex=True, inplace=True)\n",
    "data1['name'].replace(\" \", '', regex=True, inplace=True)\n",
    "data1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = data1[['name']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"../data/국민연금공단_국민연금 가입 사업장 내역_20220121.csv\")\n",
    "data['퇴직률'] = round((data['상실가입자수']/data['가입자수'])*100, 2)\n",
    "data['평균급여'] = round((data['당월고지금액']/(data['가입자수']*0.09)), 2) \n",
    "\n",
    "# 강소기업 리스트와 merge하기 위해 사업장명 통일\n",
    "data['회사이름'] = data['사업장명']\n",
    "data['회사이름'].replace(\"주식회사\", '', regex=True, inplace=True)\n",
    "data['회사이름'].replace(\"\\(주\\)\", '', regex=True, inplace=True)\n",
    "data['회사이름'].replace(\" \", '', regex=True, inplace=True)\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data[['사업장명', '사업자등록번호', '사업장업종코드명', \n",
    "            '가입자수', '상실가입자수', '퇴직률', '회사이름', '평균급여']]\n",
    "data2.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기업탐방기와 국민연금 데이터를 회사이름으로 겹치는 기업만 병합\n",
    "df_LEFT_JOIN = pd.merge(name, data2, left_on='name', right_on='회사이름', how='inner')\n",
    "df_LEFT_JOIN.head(1)\n",
    "df_LEFT_JOIN = df_LEFT_JOIN[df_LEFT_JOIN['사업장명'] != ' ']\n",
    "tmp = df_LEFT_JOIN[['사업장명', '사업자등록번호', '사업장업종코드명', '가입자수', '상실가입자수', '퇴직률', '평균급여']]\n",
    "tmp.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.to_excel(r\"../data/강소기업_급여및퇴직률.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 최종 방사형 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_excel(\"../data/강소기업_급여및퇴직률.xlsx\")\n",
    "data2 = pd.read_csv(\"../data/복지_기업별단어수.csv\")\n",
    "data3 = pd.read_csv(\"../data/뉴스_기업별단어수.csv\", encoding='cp949')\n",
    "\n",
    "data2.columns = ['사업장명', '복지']\n",
    "data3.columns = ['사업장명', '뉴스']\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사업장명 통일\n",
    "data1['회사이름'] = data1['사업장명']\n",
    "data1['회사이름'].replace(\"주식회사\", '', regex=True, inplace=True)\n",
    "data1['회사이름'].replace(\"\\(주\\)\", '', regex=True, inplace=True)\n",
    "data1['회사이름'].replace(\" \", '', regex=True, inplace=True)\n",
    "\n",
    "data2['회사이름'] = data2['사업장명']\n",
    "data2['회사이름'].replace(\"주식회사\", '', regex=True, inplace=True)\n",
    "data2['회사이름'].replace(\"\\(주\\)\", '', regex=True, inplace=True)\n",
    "data2['회사이름'].replace(\" \", '', regex=True, inplace=True)\n",
    "\n",
    "data3['회사이름'] = data3['사업장명']\n",
    "data3['회사이름'].replace(\"주식회사\", '', regex=True, inplace=True)\n",
    "data3['회사이름'].replace(\"\\(주\\)\", '', regex=True, inplace=True)\n",
    "data3['회사이름'].replace(\" \", '', regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_data = pd.merge(data1, data2[['복지', '회사이름']], left_on='회사이름', right_on='회사이름', how = 'outer')\n",
    "merge_data2 = pd.merge(merge_data, data3[['뉴스', '회사이름']], left_on='회사이름', right_on='회사이름', how = 'outer')\n",
    "merge_data2 = merge_data2.dropna(subset=['사업장명']).drop(['회사이름'], axis=1)\n",
    "merge_data2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 복지 단어 개수가 카운트 되지 않은 기업 -> 0으로 초기화\n",
    "merge_data2['복지'] = merge_data2['복지'].apply(lambda x : 0 if str(x) == 'nan' else x)\n",
    "\n",
    "# 뉴스 단어 개수가 카운트 되지 않은 기업 -> 0으로 초기화\n",
    "merge_data2['뉴스'] = merge_data2['뉴스'].apply(lambda x : 0 if str(x) == 'nan' else x)\n",
    "\n",
    "print(merge_data2['복지'].isnull().sum(), merge_data2['뉴스'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 퇴직률이 낮을수록 높은 등급을 주기 위해 100에서 빼기 수행\n",
    "merge_data2['퇴직률'] = 100 - merge_data2['퇴직률']\n",
    "\n",
    "# 가입자가 없는 경우(분모가 0), 퇴직률 0으로 초기화\n",
    "merge_data2['퇴직률'] = merge_data2['퇴직률'].apply(lambda x : 0 if str(x) == '-inf' else x)\n",
    "merge_data2['퇴직률'] = merge_data2['퇴직률'].apply(lambda x : 0 if str(x) == 'inf' else x)\n",
    "merge_data2['퇴직률'] = merge_data2['퇴직률'].apply(lambda x : 0 if str(x) == 'nan' else x)\n",
    "\n",
    "merge_data2 = merge_data2.astype({\"퇴직률\":int})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가입자 수에 따른 등급 부여 -> 한 등급 당 동일 개수의 회사\n",
    "merge_data2['가입자수'] = pd.qcut(merge_data2['가입자수'], 5, labels = list(range(1, 6)))\n",
    "\n",
    "# 퇴직률, 평균급여, 복지, 뉴스 등급 부여 -> 구간 별 등급 부여\n",
    "merge_data2['퇴직률'] = pd.cut(merge_data2['퇴직률'], 5, labels = list(range(1, 6)))\n",
    "merge_data2['평균급여'] = pd.cut(merge_data2['평균급여'], 5, labels = list(range(1, 6)))\n",
    "merge_data2['복지'] = pd.cut(merge_data2['복지'], 5, labels = list(range(1, 6)))\n",
    "merge_data2['뉴스'] = pd.cut(merge_data2['뉴스'], 5, labels = list(range(1, 6)))\n",
    "merge_data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 태블로에서 방사형 데이터를 그리기 위해 데이터 melting\n",
    "cut_data = pd.melt(merge_data2.drop(columns=['상실가입자수']), id_vars=['사업장명', '사업자등록번호', '사업장업종코드명'])\n",
    "cut_data.columns = ['사업장명',\t'사업자등록번호',\t'사업장업종코드명',\t'항목',\t'등급']\n",
    "cut_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_data.to_excel(\"../data/방사형데이터_구간화.xlsx\", index=False, encoding = 'UTF-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 인터뷰 내용 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interview = pd.read_csv(\"../data/탐방기업_QA.csv\")\n",
    "interview['회사이름'] = interview['compNm']\n",
    "interview['회사이름'].replace(\"주식회사\", '', regex=True, inplace=True)\n",
    "interview['회사이름'].replace(\"\\(주\\)\", '', regex=True, inplace=True)\n",
    "interview['회사이름'].replace(\" \", '', regex=True, inplace=True)\n",
    "interview.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 첫번째 질문만\n",
    "interview.drop_duplicates(subset = ['busiNo', 'compNm'], keep='first', ignore_index=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radar_data = cut_data\n",
    "\n",
    "for row in interview.iterrows():\n",
    "    busiNo = int(str(row[1]['busiNo'])[:6])\n",
    "    comp = row[1]['회사이름']\n",
    "\n",
    "    # 인터뷰한 기업의 등급 정보\n",
    "    interv_comp = radar_data[(radar_data['회사이름'] == comp)&(radar_data['사업자등록번호'] == busiNo)]\n",
    "    for vals in interv_comp.iterrows():\n",
    "        idx = vals[0] # index\n",
    "        if '소개' in row[1]['Q']:\n",
    "            radar_data.at[idx, 'Q'] = '기업 정보'\n",
    "        else:\n",
    "            radar_data.at[idx, 'Q'] = row[1]['Q']\n",
    "            # print(row[1]['Q'])\n",
    "        radar_data.at[idx, 'A'] = row[1]['A'].replace(\"\\r\\n\", \" \")\n",
    "\n",
    "radar_data = radar_data.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radar_data.to_excel(\"./data/방사형데이터_인터뷰추가.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
